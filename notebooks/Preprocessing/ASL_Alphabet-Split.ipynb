{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test/Train set\n",
    "\n",
    "This will take the original training set (and/or images scraped from movies) and create a test/training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive histogram equalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from terminaltables import AsciiTable\n",
    "import os\n",
    "import shutil\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = os.path.join('..', '..', 'data')\n",
    "\n",
    "ORIGINAL_DATA = os.path.join(DATA_DIRECTORY, 'original', 'asl-alphabet')\n",
    "FABRICATED_DATA = os.path.join(DATA_DIRECTORY, 'fabricated', 'asl_alphabet')\n",
    "\n",
    "ORIGINAL_TRAIN_DIR = os.path.join(ORIGINAL_DATA, 'asl_alphabet_train')\n",
    "IMAGES_FROM_MOVIES_DIR = os.path.join(DATA_DIRECTORY, 'fabricated', 'movies')\n",
    "\n",
    "NEW_TRAIN_DIR = os.path.join(FABRICATED_DATA, 'split_asl_alphabet_train')\n",
    "NEW_TEST_DIR = os.path.join(FABRICATED_DATA, 'split_asl_alphabet_test')\n",
    "\n",
    "FABRICATED_DIRS = [\n",
    "    NEW_TRAIN_DIR,\n",
    "    NEW_TEST_DIR\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TRAIN_SPLIT = .95 # Train Size\n",
    "DRY_RUN = False\n",
    "MAX_PER_CLASS = 350\n",
    "DELETE_FIRST = True # Delete new folders before starting\n",
    "\n",
    "TRAIN_WITH_MOVIES_IMAGES = True\n",
    "TRAIN_WITH_ORIGINAL_IMAGES = False\n",
    "#MAX_PER_CLASS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through training folder, get just the filenames of each folder. Split these files into test/training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/141291/how-to-list-only-top-level-directories-in-python\n",
    "# We don't want all files, just \"folders\" from the given directory\n",
    "def get_real_directories(directory):\n",
    "    return next(os.walk(directory))[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sign_names_from_directory(directory):\n",
    "    try:\n",
    "        return get_real_directories(directory)\n",
    "    except:\n",
    "        print('{} directory appears to not exist'.format(directory))\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with images from movies\n",
      "41 total signs\n"
     ]
    }
   ],
   "source": [
    "# A, B, C, D, DELETE, etc\n",
    "TRAIN_NAMES = get_sign_names_from_directory(ORIGINAL_TRAIN_DIR)\n",
    "MOVIE_NAMES = get_sign_names_from_directory(IMAGES_FROM_MOVIES_DIR)\n",
    "\n",
    "TRAIN_PATHS = [os.path.join(ORIGINAL_TRAIN_DIR, name) for name in TRAIN_NAMES]\n",
    "MOVIE_PATHS = [os.path.join(IMAGES_FROM_MOVIES_DIR, name) for name in MOVIE_NAMES]\n",
    "\n",
    "ASL_FOLDERS = []\n",
    "ASL_SIGNS_NAMES = []\n",
    "if TRAIN_WITH_ORIGINAL_IMAGES:\n",
    "    print('Training with original images')\n",
    "    ASL_FOLDERS = ASL_FOLDERS + TRAIN_PATHS\n",
    "    ASL_SIGNS_NAMES = ASL_SIGNS_NAMES + TRAIN_NAMES\n",
    "if TRAIN_WITH_MOVIES_IMAGES:\n",
    "    print('Training with images from movies')\n",
    "    ASL_FOLDERS = ASL_FOLDERS + MOVIE_PATHS\n",
    "    ASL_SIGNS_NAMES = ASL_SIGNS_NAMES + MOVIE_NAMES\n",
    "\n",
    "print('{} total signs'.format(len(ASL_FOLDERS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_folders_with_letter(letter):\n",
    "    for test_dir in FABRICATED_DIRS:\n",
    "        test_dir_with_letter = os.path.join(test_dir, letter)\n",
    "        try:\n",
    "            os.makedirs(test_dir_with_letter)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def make_sure_folders_exist():\n",
    "    for sign in ASL_SIGNS_NAMES:\n",
    "        create_test_folders_with_letter(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_for_batch_type(batch_type='train'):\n",
    "    if batch_type == 'train':\n",
    "        return NEW_TRAIN_DIR\n",
    "    else:\n",
    "        return NEW_TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(sign, infolder, files, batch_type='train'):\n",
    "    for file in files:\n",
    "        infile = os.path.join(infolder, file)\n",
    "        new_dir = get_folder_for_batch_type(batch_type)\n",
    "        outdir = os.path.join(new_dir, sign)\n",
    "        outfile = os.path.join(outdir, file)\n",
    "        shutil.copyfile(infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folders(folders):\n",
    "    for folder in folders:\n",
    "        shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DELETE_FIRST:\n",
    "    try:\n",
    "        delete_folders(FABRICATED_DIRS)\n",
    "    except:\n",
    "        print('It looks like the folders may not exist (no need to delete)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may throw errors if directories already exist\n",
    "try:\n",
    "    make_sure_folders_exist()\n",
    "except:\n",
    "    print('Cannot create all folders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_n_items_from_list(items, numer_of_items):\n",
    "    if len(items) < numer_of_items:\n",
    "        return items\n",
    "    return random.sample(items, numer_of_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_filenames(directory):\n",
    "    all_filenames = os.listdir(directory)\n",
    "    if MAX_PER_CLASS is None:\n",
    "        return [all_filenames, 0]\n",
    "    else:\n",
    "        if len(all_filenames) < MAX_PER_CLASS: # A caps is not necessary\n",
    "            return [all_filenames, 0]\n",
    "        items_lost = (len(all_filenames) - MAX_PER_CLASS)\n",
    "        return [get_random_n_items_from_list(all_filenames, MAX_PER_CLASS), items_lost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kjprice/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+------------+\n",
      "| sign | train | test    | files_lost |\n",
      "+------+-------+---------+------------+\n",
      "| 332  | 18    | father  | 5          |\n",
      "| 332  | 18    | R       | 2          |\n",
      "| 332  | 18    | U       | 12         |\n",
      "| 332  | 18    | 9       | 32         |\n",
      "| 309  | 17    | 7       | 0          |\n",
      "| 332  | 18    | I       | 68         |\n",
      "| 298  | 16    | N       | 0          |\n",
      "| 332  | 18    | G       | 12         |\n",
      "| 332  | 18    | 6       | 25         |\n",
      "| 332  | 18    | Z       | 27         |\n",
      "| 286  | 16    | 1       | 0          |\n",
      "| 332  | 18    | 10      | 13         |\n",
      "| 332  | 18    | 8       | 35         |\n",
      "| 304  | 16    | T       | 0          |\n",
      "| 332  | 18    | S       | 27         |\n",
      "| 287  | 16    | A       | 0          |\n",
      "| 317  | 17    | F       | 0          |\n",
      "| 332  | 18    | O       | 4          |\n",
      "| 332  | 18    | H       | 0          |\n",
      "| 139  | 8     | me      | 0          |\n",
      "| 126  | 7     | my      | 0          |\n",
      "| 332  | 18    | nothing | 175        |\n",
      "| 308  | 17    | mother  | 0          |\n",
      "| 332  | 18    | M       | 94         |\n",
      "| 332  | 18    | J       | 67         |\n",
      "| 332  | 18    | C       | 30         |\n",
      "| 294  | 16    | D       | 0          |\n",
      "| 332  | 18    | V       | 44         |\n",
      "| 332  | 18    | Q       | 24         |\n",
      "| 317  | 17    | 4       | 0          |\n",
      "| 332  | 18    | X       | 10         |\n",
      "| 332  | 18    | 3       | 64         |\n",
      "| 304  | 16    | E       | 0          |\n",
      "| 332  | 18    | B       | 30         |\n",
      "| 332  | 18    | K       | 32         |\n",
      "| 332  | 18    | L       | 46         |\n",
      "| 288  | 16    | 2       | 0          |\n",
      "| 294  | 16    | Y       | 0          |\n",
      "| 260  | 14    | 5       | 0          |\n",
      "| 285  | 15    | P       | 0          |\n",
      "| 327  | 18    | W       | 0          |\n",
      "+------+-------+---------+------------+\n",
      "CPU times: user 1.19 s, sys: 3.57 s, total: 4.77 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "# take random samples from the original dataset and create test/train images out of this\n",
    "def split_data():\n",
    "    if DRY_RUN:\n",
    "        print('This is just a dry run - will not create files')\n",
    "        print()\n",
    "    table_headers = [['sign', 'train', 'test', 'files_lost']]\n",
    "    table_rows = []\n",
    "    for sign, input_folder_path in zip(ASL_SIGNS_NAMES, ASL_FOLDERS):\n",
    "        [filenames, files_lost] = retrieve_filenames(input_folder_path)\n",
    "        train, test = train_test_split(filenames, train_size=TEST_TRAIN_SPLIT)\n",
    "        table_rows.append([len(train), len(test), sign, files_lost])\n",
    "        if not DRY_RUN:\n",
    "            copy_files(sign, input_folder_path, train, 'train')\n",
    "            copy_files(sign, input_folder_path, test, 'test')\n",
    "    table_data = table_headers + table_rows\n",
    "    table = AsciiTable(table_data)\n",
    "    print(table.table)\n",
    "\n",
    "%time split_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
