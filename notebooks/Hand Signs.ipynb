{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, copy, ntpath, datetime\n",
    "import keras\n",
    "from keras import models, layers, callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import boto3\n",
    "import glob\n",
    "import ntpath\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE=(150, 150, 3)\n",
    "\n",
    "LIMIT_BATCHES = 2\n",
    "#LIMIT_BATCHES = None\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 20\n",
    "NUM_CLASSES = 29\n",
    "\n",
    "# PRETRAIN_MODEL = 'conv_base_local'\n",
    "# PRETRAIN_MODEL = 'conv_base_vgg16'\n",
    "PRETRAIN_MODEL = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FilePath Information\n",
    "#DATA_DIR = '../data'\n",
    "#ASL_ALPHABET_DATASET = os.path.join(DATA_DIR, 'asl_alphabet/processed_original_test')\n",
    "\n",
    "\n",
    "# SAVED_MODEL_DIR = os.path.join(DATA_DIR, 'models/asl_alphabet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FilePath Information\n",
    "DATA_DIR = '../data'\n",
    "\n",
    "LOCAL_DATASET_DIR = os.path.join(DATA_DIR, 'asl_alphabet')\n",
    "\n",
    "TRAIN_DATASET_NAME = 'processed_asl_train'\n",
    "LOCAL_TRAIN_DIR = os.path.join(LOCAL_DATASET_DIR, TRAIN_DATASET_NAME)\n",
    "\n",
    "#NEW_TRAIN_DIR = '/tmp/asl_alphabet_train'\n",
    "#NEW_TEST_DIR = '/tmp/asl_alphabet_test'\n",
    "\n",
    "#FABRICATED_DIRS = [\n",
    "#    NEW_TRAIN_DIR,\n",
    "#    NEW_TEST_DIR\n",
    "#]\n",
    "\n",
    "SAVED_MODEL_DIR = os.path.join(DATA_DIR, 'models/asl_alphabet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processed_inverted_rgb_ahe_test', 'processed_ahe_asl_test', 'processed_rgb_ahe_test', 'processed_asl_train', 'processed_grayscale_test', 'processed_ahe_inverted_asl_test', 'processed_original_test']\n"
     ]
    }
   ],
   "source": [
    "AVAILABLE_DATASETS = os.listdir(LOCAL_DATASET_DIR)\n",
    "print(AVAILABLE_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have one training set and 6 test sets\n"
     ]
    }
   ],
   "source": [
    "if not TRAIN_DATASET_NAME in AVAILABLE_DATASETS:\n",
    "  raise Exception('we are expecting to see {} as one of the available datasets'.format(TRAIN_DATASET_NAME))\n",
    "TEST_DATASET_NAMES = [dataset for dataset in AVAILABLE_DATASETS if dataset != TRAIN_DATASET_NAME]\n",
    "print('We have one training set and {} test sets'.format(len(TEST_DATASET_NAMES)))\n",
    "LOCAL_TEST_DIRS = [os.path.join(LOCAL_DATASET_DIR, name) for name in TEST_DATASET_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sign_folders(from_folder):\n",
    "  # https://stackoverflow.com/questions/973473/getting-a-list-of-all-subdirectories-in-the-current-directory\n",
    "  folders = next(os.walk(from_folder))[1]\n",
    "  return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A, B, C, D, DELETE, etc\n",
    "ASL_FOLDERS = get_sign_folders(LOCAL_TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17100 images in training dir; and 150 images in testing dir for a single class, with a total of 30 classes\n"
     ]
    }
   ],
   "source": [
    "training_length = len(os.listdir(os.path.join(LOCAL_TRAIN_DIR, 'A')))\n",
    "testing_length = len(os.listdir(os.path.join(LOCAL_TEST_DIRS[0], 'A')))\n",
    "\n",
    "num_classes = len(os.listdir(LOCAL_TRAIN_DIR))\n",
    "\n",
    "print('{} images in training dir; and {} images in testing dir for a single class, with a total of {} classes'.format(training_length, testing_length, num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_datagen(directory):\n",
    "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "  return test_datagen.flow_from_directory(\n",
    "         directory,\n",
    "         target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
    "         batch_size = BATCH_SIZE,\n",
    "         color_mode = \"rgb\",\n",
    "         class_mode='categorical'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset definition with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    )\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# end without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 446310 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "           LOCAL_TRAIN_DIR,\n",
    "           target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
    "           batch_size=BATCH_SIZE,\n",
    "           class_mode = 'categorical',\n",
    "           subset='training'\n",
    ")\n",
    "\n",
    "#create generators\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "           LOCAL_TRAIN_DIR,\n",
    "           target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
    "           batch_size=BATCH_SIZE,\n",
    "           class_mode = 'categorical',\n",
    "           subset='validation'\n",
    ")\n",
    "\n",
    "test_generators = [create_test_datagen(dir) for dir in LOCAL_TEST_DIRS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "           ASL_ALPHABET_DATASET,\n",
    "           target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
    "           batch_size=BATCH_SIZE,\n",
    "           class_mode = 'categorical',\n",
    "           subset='training'\n",
    ")\n",
    "\n",
    "#create generators\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "           ASL_ALPHABET_DATASET,\n",
    "           target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
    "           batch_size=BATCH_SIZE,\n",
    "           class_mode = 'categorical',\n",
    "           subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=IMAGE_SHAPE))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "\n",
    "#Add a classfier on top of the convnet\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "#compile the model\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = None\n",
    "\n",
    "if LIMIT_BATCHES is None:\n",
    "  steps_per_epoch_train = len(train_generator)\n",
    "  steps_per_epoch_val = len(train_generator)\n",
    "  steps_per_epoch_test = len(test_generators[0])\n",
    "else:\n",
    "  steps_per_epoch_train = LIMIT_BATCHES\n",
    "  steps_per_epoch_val = LIMIT_BATCHES\n",
    "  steps_per_epoch_test = LIMIT_BATCHES\n",
    "  \n",
    "\n",
    "history= model.fit_generator (\n",
    "           train_generator,\n",
    "           epochs = NUM_EPOCHS,\n",
    "           steps_per_epoch=steps_per_epoch_train,\n",
    "           validation_steps=steps_per_epoch_val,\n",
    "           #callbacks = callbacks_list,\n",
    "           validation_data=validation_generator,\n",
    "           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization of model performance\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values =  history_dict['val_loss']\n",
    "acc_values = history_dict['acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label = 'Training Loss')\n",
    "plt.plot(epochs,val_loss_values, 'b', label = 'Validation Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel='Epochs'\n",
    "plt.ylabel='Loss'\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs,val_acc_values, 'b', label='Validation accuracy')\n",
    "plt.xlabel = 'Epochs'\n",
    "plt.ylabel = 'Loss'\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate against each of the test generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy():\n",
    "    accuracies = []\n",
    "    for generator, _dir in zip(test_generators, LOCAL_TEST_DIRS):\n",
    "      test_loss, test_acc = model.evaluate_generator(generator, steps=steps_per_epoch_test)\n",
    "      accuracies.append(test_acc)\n",
    "      print('{}: {}'.format(_dir, test_acc))\n",
    "    return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = get_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_model_directory_exists():\n",
    "    try:\n",
    "        os.makedirs(SAVED_MODEL_DIR)\n",
    "    except:\n",
    "        print('Tried to create \"{}\" but it already exists'.format(SAVED_MODEL_DIR))\n",
    "\n",
    "def save_model():\n",
    "    ensure_model_directory_exists()\n",
    "    \n",
    "    timestamp_raw = str(datetime.datetime.now())\n",
    "    timestamp_without_milliseconds = timestamp_raw.split('.')[0]\n",
    "    \n",
    "    model_filename = '{}___{}.h5'.format(timestamp_without_milliseconds, test_accuracy)\n",
    "    model_filepath = os.path.join(SAVED_MODEL_DIR, model_filename)\n",
    "    \n",
    "    print('saving file {}'.format(model_filepath))\n",
    "\n",
    "    model.save(model_filepath)\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send text message when complete (if the environment variable \"TEXT_PHONENUMBER\" is set)\n",
    "if 'TEXT_PHONENUMBER' in os.environ:\n",
    "    text_phonenumber = os.environ['TEXT_PHONENUMBER']\n",
    "    client = boto3.client('sns')\n",
    "    client.publish(PhoneNumber=text_phonenumber, Message='Model Finished with mae {}'.format(test_accuracy))\n",
    "    print('text sent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook has been saved\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "\n",
    "def notebook_save():\n",
    "    Javascript(script)\n",
    "    \n",
    "    print('This notebook has been saved')\n",
    "notebook_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_off_instance():\n",
    "    if 'INSTANCE_ID' in os.environ:\n",
    "        client = boto3.client('ec2')\n",
    "        client.stop_instances(InstanceIds=[os.environ['INSTANCE_ID']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Largest Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally load a previous model to review (will overwrite the global \"model\" variable)\n",
    "# model = load_model('../data/models/asl_alphabet/2018-12-07 04:36:16___0.9285714030265808.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.class_indices\n",
    "class_name_by_index = {}\n",
    "for index, class_name in enumerate(validation_generator.class_indices):\n",
    "    class_name_by_index[int(index)] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_VALIDATION_IMAGES = 8698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "class_vectors = []\n",
    "\n",
    "while len(images) < NUMBER_OF_VALIDATION_IMAGES:\n",
    "    _images, _class_vectors = next(validation_generator)\n",
    "    if len(images) == 0:\n",
    "        images = _images\n",
    "        class_vectors = _class_vectors\n",
    "    else:\n",
    "        images = np.append(images, _images, axis=0)\n",
    "        class_vectors = np.append(class_vectors, _class_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = None\n",
    "true_classes = []\n",
    "predicted_classes = []\n",
    "selected_probabilities = []\n",
    "true_probabilities = []\n",
    "dissonance = []\n",
    "\n",
    "predictions = model.predict(images)\n",
    "#_probability = model.predict_proba(images)\n",
    "\n",
    "for class_vector, probability in zip(class_vectors, predictions):\n",
    "    predicted_class = probability.argmax(axis=-1)\n",
    "    true_class = class_vector.argmax(axis=-1)\n",
    "    selected_probability = probability.max()\n",
    "    true_probability = probability[true_class]\n",
    "\n",
    "    true_classes.append(true_class)\n",
    "    predicted_classes.append(predicted_class)\n",
    "    selected_probabilities.append(selected_probability)\n",
    "    true_probabilities.append(true_probability)\n",
    "    dissonance.append(selected_probability - true_probability)\n",
    "\n",
    "validations = pd.DataFrame({\n",
    "    'true_class': true_classes,\n",
    "    'selected_class': predicted_classes,\n",
    "    'true_class_name': [class_name_by_index[_class] for _class in true_classes],\n",
    "    'selected_class_name': [class_name_by_index[_class] for _class in predicted_classes],\n",
    "    'selected_probability': selected_probabilities,\n",
    "    'true_probabilities': true_probabilities,\n",
    "    'dissonance': dissonance\n",
    "})\n",
    "\n",
    "errors = validations[validations['selected_class'] != validations['true_class']].sort_values('dissonance')\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many errors are in each class\n",
    "errors_counts = errors.groupby('true_class_name') \\\n",
    "    .size() \\\n",
    "    .reset_index(name='counts')\n",
    "errors_counts.columns = ['class_name', 'error_counts']\n",
    "\n",
    "errors_counts.plot.bar(x='class_name', y='error_counts', figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = validations.groupby(['true_class_name']) \\\n",
    "    .size() \\\n",
    "    .reset_index(name='counts')\n",
    "total_counts.columns = ['class_name', 'total_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_pd = total_counts.merge(errors_counts, on='class_name')\n",
    "counts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_pd['percent_errors'] = counts_pd.error_counts / counts_pd.total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_pd.plot.bar(x='class_name', y='percent_errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[93])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
