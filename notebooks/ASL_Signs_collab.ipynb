{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL Signs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjprice/smu-capstone/blob/master/notebooks/ASL_Signs_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UFw3pyTb1Zug",
        "colab_type": "code",
        "outputId": "fa52b9c1-cb4e-42ff-8c61-b39032038eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HAnQGDSx324u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, shutil, copy, ntpath, datetime, zipfile\n",
        "import keras\n",
        "from keras import models, layers, callbacks\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import boto3\n",
        "import glob\n",
        "import ntpath\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E_uyYEWg4zJ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make sure we have GPU"
      ]
    },
    {
      "metadata": {
        "id": "NjAMzX__34lW",
        "colab_type": "code",
        "outputId": "7e572ff1-efd1-4c0c-d608-819b683c8022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o9Ou5mxYWo2Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Settings"
      ]
    },
    {
      "metadata": {
        "id": "phLs5u0-4Nyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE=(150, 150, 3)\n",
        "\n",
        "#LIMIT_BATCHES = 593\n",
        "LIMIT_BATCHES = None\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 20\n",
        "NUM_CLASSES = 29\n",
        "\n",
        "# PRETRAIN_MODEL = 'conv_base_local'\n",
        "#PRETRAIN_MODEL = VGG16\n",
        "#PRETRAIN_MODEL = VGG19\n",
        "PRETRAIN_MODEL = Xception\n",
        "#PRETRAIN_MODEL = ResNet50\n",
        "# PRETRAIN_MODEL = None\n",
        "\n",
        "USE_PREPROCESSED_IMAGES = False\n",
        "\n",
        "TEST_TRAIN_SPLIT = .95 # Train Size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSjmfPFnWzRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Set Folders"
      ]
    },
    {
      "metadata": {
        "id": "zIdRa0sm5AhF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### FilePath Information\n",
        "DATA_DIR = '/content/gdrive/My Drive/SMU/Capstone/DataSets/'\n",
        "\n",
        "LOCAL_DATASET_DIR = '/tmp/asl_alphabet'\n",
        "\n",
        "SAVED_MODEL_DIR = os.path.join(DATA_DIR, 'models/asl_alphabet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JV_VNHUaEqHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if USE_PREPROCESSED_IMAGES:\n",
        "  dataset_zip = os.path.join(DATA_DIR, 'asl_alphabet.zip')\n",
        "  local_dataset_zip = '/tmp/asl_alphabet.zip'\n",
        "  train_dataset_name = 'processed_asl_train'\n",
        "  temp_unzip_directory = '/tmp/data/fabricated/asl_alphabet'\n",
        "else:\n",
        "  dataset_zip = os.path.join(DATA_DIR, 'asl_alphabet_original.zip')\n",
        "  local_dataset_zip = '/tmp/asl_alphabet_original.zip'\n",
        "  train_dataset_name = 'split_asl_alphabet_train'\n",
        "  temp_unzip_directory = '/tmp/asl_alphabet_original/data/fabricated/asl_alphabet'\n",
        "  \n",
        "TRAIN_DATASET_NAME = train_dataset_name\n",
        "ASL_ALPHABET_DATASET_ZIP = dataset_zip\n",
        "LOCAL_DATASET_ZIP = local_dataset_zip\n",
        "LOCAL_TRAIN_DIR = os.path.join(LOCAL_DATASET_DIR, TRAIN_DATASET_NAME)\n",
        "TEMP_UNZIP_DIRECTORY = temp_unzip_directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MnC4-vwjW7-K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Download Data"
      ]
    },
    {
      "metadata": {
        "id": "Qu0T7H4yr12e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(LOCAL_DATASET_ZIP):\n",
        "  %time shutil.copy(ASL_ALPHABET_DATASET_ZIP, LOCAL_DATASET_ZIP)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f96ajmJRXAGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Extract Data"
      ]
    },
    {
      "metadata": {
        "id": "giYmqznqLeWk",
        "colab_type": "code",
        "outputId": "97d8349d-2d00-49ec-abc7-6a511a72a13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "if os.path.isdir(LOCAL_DATASET_DIR):\n",
        "  shutil.rmtree(LOCAL_DATASET_DIR)\n",
        "with zipfile.ZipFile(LOCAL_DATASET_ZIP, 'r') as zip_ref:\n",
        "    %time zip_ref.extractall('/tmp')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17.3 s, sys: 6.11 s, total: 23.4 s\n",
            "Wall time: 23.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QGPmptZOsPgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(TEMP_UNZIP_DIRECTORY):\n",
        "  print('not sure where the zip folder exported the directory but it is not where we expected')\n",
        "else:\n",
        "  shutil.move(TEMP_UNZIP_DIRECTORY, LOCAL_DATASET_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4E1HtcesI4c",
        "colab_type": "code",
        "outputId": "925d4963-ef85-471e-9ff5-268843c108e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "AVAILABLE_DATASETS = os.listdir(LOCAL_DATASET_DIR)\n",
        "print(AVAILABLE_DATASETS)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['split_asl_alphabet_train', 'split_asl_alphabet_test']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oDAeef0Rrxjv",
        "colab_type": "code",
        "outputId": "42c0e9b8-bb62-43b6-8cb9-0e666691acd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if not TRAIN_DATASET_NAME in AVAILABLE_DATASETS:\n",
        "  raise Exception('we are expecting to see {} as one of the available datasets'.format(TRAIN_DATASET_NAME))\n",
        "TEST_DATASET_NAMES = [dataset for dataset in AVAILABLE_DATASETS if dataset != TRAIN_DATASET_NAME]\n",
        "print('We have one training set and {} test sets'.format(len(TEST_DATASET_NAMES)))\n",
        "LOCAL_TEST_DIRS = [os.path.join(LOCAL_DATASET_DIR, name) for name in TEST_DATASET_NAMES]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have one training set and 1 test sets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OjHf45KsXOsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Create Split training/test data"
      ]
    },
    {
      "metadata": {
        "id": "vev8HX3nZGIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sign_folders(from_folder):\n",
        "  # https://stackoverflow.com/questions/973473/getting-a-list-of-all-subdirectories-in-the-current-directory\n",
        "  folders = next(os.walk(from_folder))[1]\n",
        "  return folders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJZYGiwnXX0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A, B, C, D, DELETE, etc\n",
        "ASL_FOLDERS = get_sign_folders(LOCAL_TRAIN_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0BMLNPEuXHzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Create Data Generators"
      ]
    },
    {
      "metadata": {
        "id": "x2CeJieJxZDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_test_datagen(directory):\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  return test_datagen.flow_from_directory(\n",
        "         directory,\n",
        "         target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
        "         batch_size = BATCH_SIZE,\n",
        "         color_mode = \"rgb\",\n",
        "         class_mode='categorical'\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvTJuHhc5DVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset definition with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zb8nTrZ25Eje",
        "colab_type": "code",
        "outputId": "7fd42af5-2188-42d6-88b0-651a65d8aa4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#create generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "           LOCAL_TRAIN_DIR,\n",
        "           target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
        "           batch_size=BATCH_SIZE,\n",
        "           class_mode = 'categorical',\n",
        "           subset='training'\n",
        ")\n",
        "\n",
        "#create generators\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "           LOCAL_TRAIN_DIR,\n",
        "           target_size = (IMAGE_SHAPE[0], IMAGE_SHAPE[0]),\n",
        "           batch_size=BATCH_SIZE,\n",
        "           class_mode = 'categorical',\n",
        "           subset='validation'\n",
        ")\n",
        "\n",
        "test_generators = [create_test_datagen(dir) for dir in LOCAL_TEST_DIRS]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 74385 images belonging to 29 classes.\n",
            "Found 8265 images belonging to 29 classes.\n",
            "Found 4350 images belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NcuHxZtKAqgx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "id": "4Ob6_zTgAoED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_pretrained_model(BASE):   \n",
        "    conv_base = BASE(weights='imagenet',\n",
        "                      include_top=False,\n",
        "                      input_shape=(IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))\n",
        "    print(conv_base.summary())\n",
        "    \n",
        "    conv_base.trainable = False\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    model.add(conv_base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dense(29, activation='sigmoid'))\n",
        "\n",
        "    optimizer = keras.optimizers.RMSprop(lr=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oPP5cfCt5IrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_blank_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=IMAGE_SHAPE))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "\n",
        "    #Add a classfier on top of the convnet\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(.5))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    #model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "    #compile the model\n",
        "    optimizer = keras.optimizers.RMSprop(lr=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2B_b7B_kAyct",
        "colab_type": "code",
        "outputId": "7db94d73-d273-49f9-832a-9024bba83134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5134
        }
      },
      "cell_type": "code",
      "source": [
        "if not PRETRAIN_MODEL:\n",
        "    model = create_blank_model()\n",
        "else:\n",
        "    model = create_pretrained_model(PRETRAIN_MODEL)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 36, 36, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 18, 18, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 18, 18, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 9, 9, 728)    186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 728)    2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 1024)   745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 5, 5, 1024)   4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 29)                7453      \n",
            "=================================================================\n",
            "Total params: 33,976,389\n",
            "Trainable params: 13,114,909\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1YCgPt1OLp22",
        "colab_type": "code",
        "outputId": "8efcea6f-acbf-4b1a-82ce-3f88108bcc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "steps_per_epoch = None\n",
        "\n",
        "if LIMIT_BATCHES is None:\n",
        "  steps_per_epoch_train = len(train_generator)\n",
        "  steps_per_epoch_val = len(validation_generator)\n",
        "  steps_per_epoch_test = len(test_generators[0])\n",
        "else:\n",
        "  steps_per_epoch_train = LIMIT_BATCHES\n",
        "  steps_per_epoch_val = (LIMIT_BATCHES / len(train_generator)) * len(validation_generator)\n",
        "  steps_per_epoch_test = (LIMIT_BATCHES / len(train_generator)) * len(test_generators[0])\n",
        "\n",
        "print('total batches {}'.format(len(train_generator)))\n",
        "print('steps_per_epoch_train {}'.format(steps_per_epoch_train))\n",
        "print('steps_per_epoch_test {}'.format(steps_per_epoch_test))\n",
        "print('steps_per_epoch_val {}'.format(steps_per_epoch_val))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total batches 3720\n",
            "steps_per_epoch_train 3720\n",
            "steps_per_epoch_test 218\n",
            "steps_per_epoch_val 414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NMfeDeRO5RU3",
        "colab_type": "code",
        "outputId": "89ae24a4-543f-4f74-b61a-6dfd20057eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "history= model.fit_generator (\n",
        "train_generator,\n",
        "epochs = NUM_EPOCHS,\n",
        "steps_per_epoch=steps_per_epoch_train,\n",
        "validation_steps=steps_per_epoch_val,\n",
        "#callbacks = callbacks_list,\n",
        "validation_data=validation_generator,\n",
        "verbose=1 \\\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3720/3720 [==============================] - 707s 190ms/step - loss: 1.5749 - acc: 0.5742 - val_loss: 7.7655 - val_acc: 0.1685\n",
            "Epoch 2/10\n",
            "3720/3720 [==============================] - 702s 189ms/step - loss: 1.1095 - acc: 0.6995 - val_loss: 8.3507 - val_acc: 0.1869\n",
            "Epoch 3/10\n",
            "3720/3720 [==============================] - 704s 189ms/step - loss: 0.9583 - acc: 0.7375 - val_loss: 8.5505 - val_acc: 0.1860\n",
            "Epoch 4/10\n",
            "3720/3720 [==============================] - 705s 189ms/step - loss: 0.8634 - acc: 0.7609 - val_loss: 9.5710 - val_acc: 0.1625\n",
            "Epoch 5/10\n",
            "3720/3720 [==============================] - 698s 188ms/step - loss: 0.0641 - acc: 0.0952 - val_loss: 1.1921e-07 - val_acc: 0.0345\n",
            "Epoch 6/10\n",
            "3720/3720 [==============================] - 694s 187ms/step - loss: 1.1921e-07 - acc: 0.0345 - val_loss: 1.1921e-07 - val_acc: 0.0345\n",
            "Epoch 7/10\n",
            "3720/3720 [==============================] - 705s 189ms/step - loss: 1.1921e-07 - acc: 0.0345 - val_loss: 1.1921e-07 - val_acc: 0.0345\n",
            "Epoch 8/10\n",
            "3720/3720 [==============================] - 703s 189ms/step - loss: 1.1921e-07 - acc: 0.0345 - val_loss: 1.1921e-07 - val_acc: 0.0345\n",
            "Epoch 9/10\n",
            "3720/3720 [==============================] - 705s 189ms/step - loss: 1.1921e-07 - acc: 0.0345 - val_loss: 1.1921e-07 - val_acc: 0.0345\n",
            "Epoch 10/10\n",
            "3720/3720 [==============================] - 705s 190ms/step - loss: 1.1921e-07 - acc: 0.0345 - val_loss: 1.1921e-07 - val_acc: 0.0345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "soviW5rN5UKG",
        "colab_type": "code",
        "outputId": "4c4f2638-4d5c-4ae3-8856-d7c3124f8764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "#visualization of model performance\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values =  history_dict['val_loss']\n",
        "acc_values = history_dict['acc']\n",
        "\n",
        "epochs = range(1, len(acc_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label = 'Training Loss')\n",
        "plt.plot(epochs,val_loss_values, 'b', label = 'Validation Loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.xlabel='Epochs'\n",
        "plt.ylabel='Loss'\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFZCAYAAADZ6SWdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7b60607710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u9k7xD8S5VWN",
        "colab_type": "code",
        "outputId": "e478bb26-ab1f-48f5-8987-c58c23b117f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs,val_acc_values, 'b', label='Validation accuracy')\n",
        "plt.xlabel = 'Epochs'\n",
        "plt.ylabel = 'Loss'\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7b605fce10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4tLl5VA5evNq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validate against each of the test generators"
      ]
    },
    {
      "metadata": {
        "id": "3jVBPSk4eT0i",
        "colab_type": "code",
        "outputId": "32ea46f7-2c44-46ce-fd4f-f114d9eaa015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "for generator, _dir in zip(test_generators, LOCAL_TEST_DIRS):\n",
        "  test_loss, test_acc = model.evaluate_generator(generator, steps=steps_per_epoch_test)\n",
        "  print('{}: {}'.format(_dir, test_acc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/asl_alphabet/split_asl_alphabet_test: 0.034482759237289426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kyC1m6UJ_33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}